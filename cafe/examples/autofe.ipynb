{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "da41284c",
      "metadata": {
        "id": "da41284c"
      },
      "source": [
        "\n",
        "# Demonstração do AutoFE: Engenharia Automática de Features\n",
        "\n",
        "Este notebook demonstra o funcionamento do **AutoFE**, um sistema automatizado de engenharia de features, pré-processamento e validação de modelos.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Primeiro, vamos instalar o CAFE e importar as bibliotecas necessárias."
      ],
      "metadata": {
        "id": "DzlxSSAb7IeC"
      },
      "id": "DzlxSSAb7IeC"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install cafe-autofe"
      ],
      "metadata": {
        "id": "IaJkSpympyQ2"
      },
      "id": "IaJkSpympyQ2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6fd8af05",
      "metadata": {
        "id": "6fd8af05"
      },
      "outputs": [],
      "source": [
        "# Instalar CAFE (descomente para instalar)\n",
        "# !pip install cafe-autofe\n",
        "\n",
        "# Importações\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, r2_score, mean_squared_error\n",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
        "\n",
        "# Importações do CAFE\n",
        "from cafe import (\n",
        "    PreProcessor,\n",
        "    FeatureEngineer,\n",
        "    PerformanceValidator,\n",
        "    DataPipeline,\n",
        "    Explorer\n",
        ")\n",
        "\n",
        "# Configuração de visualização\n",
        "plt.style.use('ggplot')\n",
        "sns.set(style=\"whitegrid\")\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos carregar um conjunto de dados para nosso exemplo. Você pode substituir este código para carregar seus próprios dados."
      ],
      "metadata": {
        "id": "m8JXf3lL7L3W"
      },
      "id": "m8JXf3lL7L3W"
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ay4VZoso7BIQ"
      },
      "id": "ay4VZoso7BIQ"
    },
    {
      "cell_type": "code",
      "source": [
        "# Opção 1: Carregar um dataset de exemplo do scikit-learn\n",
        "from sklearn.datasets import load_wine\n",
        "wine = load_wine()\n",
        "df = pd.DataFrame(wine.data, columns=wine.feature_names)\n",
        "df['target'] = wine.target\n",
        "task_type = 'classification'\n",
        "target_col = 'target'\n",
        "\n",
        "# Opção 2: Carregar dados de um arquivo CSV (descomente e ajuste conforme necessário)\n",
        "# df = pd.read_csv('seu_arquivo.csv')\n",
        "# task_type = 'classification'  # ou 'regression' dependendo do seu problema\n",
        "# target_col = 'nome_da_coluna_alvo'\n",
        "\n",
        "print(f\"Dataset carregado: {df.shape[0]} amostras, {df.shape[1]} colunas\")\n",
        "df.head()"
      ],
      "metadata": {
        "id": "xt8GYsbu7OP6"
      },
      "id": "xt8GYsbu7OP6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exploração e Análise de Dados"
      ],
      "metadata": {
        "id": "Nxd7KUVD7Vwj"
      },
      "id": "Nxd7KUVD7Vwj"
    },
    {
      "cell_type": "code",
      "source": [
        "# Informações gerais sobre o DataFrame\n",
        "print(\"Informações do DataFrame:\")\n",
        "print(f\"Linhas: {df.shape[0]}, Colunas: {df.shape[1]}\")\n",
        "print(\"\\nTipos de dados:\")\n",
        "print(df.dtypes)\n",
        "\n",
        "# Estatísticas descritivas\n",
        "print(\"\\nEstatísticas descritivas:\")\n",
        "df.describe().round(2)"
      ],
      "metadata": {
        "id": "wUxeWB3w7Wwu"
      },
      "id": "wUxeWB3w7Wwu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Para classificação\n",
        "if task_type == 'classification':\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    sns.countplot(x=target_col, data=df)\n",
        "    plt.title('Distribuição das Classes')\n",
        "    plt.ylabel('Contagem')\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"Contagem de classes:\\n{df[target_col].value_counts()}\")\n",
        "\n",
        "# Para regressão\n",
        "elif task_type == 'regression':\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.histplot(df[target_col], kde=True)\n",
        "    plt.title('Distribuição da Variável Alvo')\n",
        "    plt.xlabel(target_col)\n",
        "    plt.ylabel('Frequência')\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"Estatísticas da variável alvo:\\n{df[target_col].describe()}\")"
      ],
      "metadata": {
        "id": "Qx5eza207hsu"
      },
      "id": "Qx5eza207hsu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "LpACGhCd7hKa"
      },
      "id": "LpACGhCd7hKa"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verificação de Valores Ausentes"
      ],
      "metadata": {
        "id": "SRhf9fLh8TP9"
      },
      "id": "SRhf9fLh8TP9"
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificar valores ausentes\n",
        "missing_values = df.isnull().sum()\n",
        "missing_percent = (missing_values / len(df)) * 100\n",
        "\n",
        "# Criar DataFrame com informações sobre valores ausentes\n",
        "missing_info = pd.DataFrame({\n",
        "    'Valores Ausentes': missing_values,\n",
        "    'Percentual (%)': missing_percent.round(2)\n",
        "})\n",
        "\n",
        "# Exibir apenas colunas com valores ausentes\n",
        "if missing_values.sum() > 0:\n",
        "    print(\"Colunas com valores ausentes:\")\n",
        "    display(missing_info[missing_info['Valores Ausentes'] > 0])\n",
        "else:\n",
        "    print(\"Não há valores ausentes no dataset!\")"
      ],
      "metadata": {
        "id": "vYwmA0id8Sbu"
      },
      "id": "vYwmA0id8Sbu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exploração de Correlações"
      ],
      "metadata": {
        "id": "8w4VZvCI8X5h"
      },
      "id": "8w4VZvCI8X5h"
    },
    {
      "cell_type": "code",
      "source": [
        "# Matriz de correlação\n",
        "plt.figure(figsize=(12, 10))\n",
        "corr_matrix = df.corr()\n",
        "mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
        "sns.heatmap(corr_matrix, mask=mask, cmap='coolwarm', annot=False,\n",
        "            center=0, square=True, linewidths=.5)\n",
        "plt.title('Matriz de Correlação')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Correlações com a variável alvo\n",
        "if target_col in df.columns:\n",
        "    target_corr = corr_matrix[target_col].sort_values(ascending=False)\n",
        "\n",
        "    # Criar gráfico de barras para correlações com o target\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    target_corr.drop(target_col).plot(kind='bar')\n",
        "    plt.title(f'Correlação com {target_col}')\n",
        "    plt.ylabel('Coeficiente de Correlação')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "Tk19RDU48bmO"
      },
      "id": "Tk19RDU48bmO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Visualização de Recursos Principais"
      ],
      "metadata": {
        "id": "FqJ7Ldc68nwi"
      },
      "id": "FqJ7Ldc68nwi"
    },
    {
      "cell_type": "code",
      "source": [
        "# Selecionar as features mais correlacionadas com o target\n",
        "if target_col in df.columns:\n",
        "    top_features = target_corr.drop(target_col).abs().sort_values(ascending=False).head(5).index.tolist()\n",
        "\n",
        "    # Visualizar distribuição das principais features\n",
        "    plt.figure(figsize=(15, 10))\n",
        "    for i, feature in enumerate(top_features, 1):\n",
        "        plt.subplot(2, 3, i)\n",
        "\n",
        "        # Para classificação\n",
        "        if task_type == 'classification':\n",
        "            for target_value in df[target_col].unique():\n",
        "                sns.kdeplot(df[df[target_col] == target_value][feature],\n",
        "                            label=f'Classe {target_value}')\n",
        "            plt.title(f'Distribuição de {feature} por Classe')\n",
        "            plt.legend()\n",
        "\n",
        "        # Para regressão\n",
        "        else:\n",
        "            plt.scatter(df[feature], df[target_col], alpha=0.5)\n",
        "            plt.title(f'{feature} vs {target_col}')\n",
        "            plt.xlabel(feature)\n",
        "            plt.ylabel(target_col)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "CB2PO3T18pAL"
      },
      "id": "CB2PO3T18pAL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Pré-processamento com CAFE"
      ],
      "metadata": {
        "id": "G4ys01Y78xSU"
      },
      "id": "G4ys01Y78xSU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuração para o preprocessador\n",
        "preprocessor_config = {\n",
        "    'missing_values_strategy': 'median',  # Estratégia para valores ausentes\n",
        "    'outlier_method': 'iqr',              # Método para tratamento de outliers\n",
        "    'categorical_strategy': 'onehot',     # Estratégia para codificação de variáveis categóricas\n",
        "    'scaling': 'standard',                # Método de normalização/padronização\n",
        "    'verbosity': 1                        # Nível de detalhamento dos logs\n",
        "}\n",
        "\n",
        "# Criar e aplicar o preprocessador\n",
        "preprocessor = PreProcessor(preprocessor_config)\n",
        "df_preprocessed = preprocessor.fit_transform(df, target_col=target_col)\n",
        "\n",
        "print(f\"DataFrame original: {df.shape}\")\n",
        "print(f\"DataFrame pré-processado: {df_preprocessed.shape}\")\n",
        "df_preprocessed.head()"
      ],
      "metadata": {
        "id": "wJqgAiBw83RF"
      },
      "id": "wJqgAiBw83RF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Configuração da Engenharia de Features"
      ],
      "metadata": {
        "id": "SQ447ByW9EXR"
      },
      "id": "SQ447ByW9EXR"
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuração para o engenheiro de features\n",
        "feature_engineer_config = {\n",
        "    'correlation_threshold': 0.8,     # Limiar para remoção de features altamente correlacionadas\n",
        "    'generate_features': True,        # Gerar features polinomiais\n",
        "    'feature_selection': 'kbest',     # Método de seleção de features\n",
        "    'feature_selection_params': {     # Parâmetros específicos para a seleção de features\n",
        "        'k': 10                       # Número de features a selecionar\n",
        "    },\n",
        "    'task': task_type,                # Tipo de tarefa (classificação ou regressão)\n",
        "    'verbosity': 1                    # Nível de detalhamento dos logs\n",
        "}\n",
        "\n",
        "# Criar e aplicar o engenheiro de features\n",
        "feature_engineer = FeatureEngineer(feature_engineer_config)\n",
        "df_engineered = feature_engineer.fit_transform(df_preprocessed, target_col=target_col)\n",
        "\n",
        "print(f\"DataFrame pré-processado: {df_preprocessed.shape}\")\n",
        "print(f\"DataFrame após engenharia de features: {df_engineered.shape}\")\n",
        "df_engineered.head()"
      ],
      "metadata": {
        "id": "_Mo59MlI9HLw"
      },
      "id": "_Mo59MlI9HLw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Validação de Performance"
      ],
      "metadata": {
        "id": "6I7hII-s9Vux"
      },
      "id": "6I7hII-s9Vux"
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuração do validador de performance\n",
        "validator_config = {\n",
        "    'max_performance_drop': 0.05,  # Máxima queda de performance permitida (5%)\n",
        "    'cv_folds': 5,                 # Número de folds para validação cruzada\n",
        "    'metric': 'accuracy' if task_type == 'classification' else 'r2',\n",
        "    'task': task_type,             # Tipo de tarefa\n",
        "    'verbose': True                # Mostrar logs detalhados\n",
        "}\n",
        "\n",
        "# Separar features e target\n",
        "X_original = df.drop(columns=[target_col])\n",
        "X_engineered = df_engineered.drop(columns=[target_col])\n",
        "y = df[target_col]\n",
        "\n",
        "# Criar e aplicar o validador\n",
        "validator = PerformanceValidator(validator_config)\n",
        "validation_results = validator.evaluate(X_original, y, X_engineered)\n",
        "\n",
        "# Mostrar resultados da validação\n",
        "print(\"\\nResultados da Validação:\")\n",
        "print(f\"Performance dataset original: {validation_results['performance_original']:.4f}\")\n",
        "print(f\"Performance dataset transformado: {validation_results['performance_transformed']:.4f}\")\n",
        "print(f\"Diferença: {validation_results['performance_diff_pct']:.2f}%\")\n",
        "print(f\"Melhor dataset: {validation_results['best_choice'].upper()}\")\n",
        "print(f\"Redução de features: {validation_results['feature_reduction']*100:.1f}%\")"
      ],
      "metadata": {
        "id": "_p20TExf9U32"
      },
      "id": "_p20TExf9U32",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Usando o Pipeline Completo"
      ],
      "metadata": {
        "id": "Y3A1DBGd9gi6"
      },
      "id": "Y3A1DBGd9gi6"
    },
    {
      "cell_type": "code",
      "source": [
        "# Criar pipeline completo com os componentes configurados\n",
        "pipeline = DataPipeline(\n",
        "    preprocessor_config=preprocessor_config,\n",
        "    feature_engineer_config=feature_engineer_config,\n",
        "    validator_config=validator_config,\n",
        "    auto_validate=True  # Ativar validação automática\n",
        ")\n",
        "\n",
        "# Aplicar pipeline completo\n",
        "df_transformed = pipeline.fit_transform(df, target_col=target_col)\n",
        "\n",
        "print(f\"Dataset original: {df.shape}\")\n",
        "print(f\"Dataset transformado: {df_transformed.shape}\")\n",
        "df_transformed.head()"
      ],
      "metadata": {
        "id": "Aa5icOKl9hNH"
      },
      "id": "Aa5icOKl9hNH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Usando o Explorer para Otimização Automática\n",
        "\n"
      ],
      "metadata": {
        "id": "nvVIzitx9v1S"
      },
      "id": "nvVIzitx9v1S"
    },
    {
      "cell_type": "code",
      "source": [
        "# Criar e aplicar o Explorer para encontrar a melhor configuração\n",
        "explorer = Explorer(target_col=target_col)\n",
        "best_data = explorer.analyze_transformations(df)\n",
        "\n",
        "# Obter a configuração ótima\n",
        "best_config = explorer.get_best_pipeline_config()\n",
        "\n",
        "print(\"Melhor configuração encontrada pelo Explorer:\")\n",
        "print(\"\\nConfiguração do Preprocessador:\")\n",
        "for key, value in best_config.get('preprocessor_config', {}).items():\n",
        "    print(f\"- {key}: {value}\")\n",
        "\n",
        "print(\"\\nConfiguração do Engenheiro de Features:\")\n",
        "for key, value in best_config.get('feature_engineer_config', {}).items():\n",
        "    print(f\"- {key}: {value}\")\n",
        "\n",
        "# Visualizar árvore de transformações\n",
        "explorer.visualize_transformations()\n",
        "\n",
        "# Estatísticas das transformações\n",
        "transformation_stats = explorer.get_transformation_statistics()\n",
        "print(\"\\nEstatísticas das Transformações:\")\n",
        "for key, value in transformation_stats.items():\n",
        "    if not isinstance(value, (list, dict)):\n",
        "        print(f\"- {key}: {value}\")\n",
        "\n",
        "# Criar pipeline com a configuração ótima\n",
        "optimal_pipeline = explorer.create_optimal_pipeline()\n",
        "df_optimal = optimal_pipeline.fit_transform(df, target_col=target_col)\n",
        "\n",
        "print(f\"\\nDataset original: {df.shape}\")\n",
        "print(f\"Dataset com transformação ótima: {df_optimal.shape}\")"
      ],
      "metadata": {
        "id": "0e4N9RYX9wZm"
      },
      "id": "0e4N9RYX9wZm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Divisão em Treino e Teste"
      ],
      "metadata": {
        "id": "ZQclaHbz_86-"
      },
      "id": "ZQclaHbz_86-"
    },
    {
      "cell_type": "code",
      "source": [
        "# Usar o dataset transformado pelo pipeline ótimo\n",
        "X = df_optimal.drop(columns=[target_col])\n",
        "y = df_optimal[target_col]\n",
        "\n",
        "# Dividir em treino e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y if task_type == 'classification' else None\n",
        ")\n",
        "\n",
        "print(f\"Conjunto de treino: {X_train.shape}\")\n",
        "print(f\"Conjunto de teste: {X_test.shape}\")"
      ],
      "metadata": {
        "id": "gpVgf0aV_7sJ"
      },
      "id": "gpVgf0aV_7sJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Treinamento e Avaliação do Modelo"
      ],
      "metadata": {
        "id": "NX_PcHMxACXM"
      },
      "id": "NX_PcHMxACXM"
    },
    {
      "cell_type": "code",
      "source": [
        "# Escolher o modelo adequado com base no tipo de tarefa\n",
        "if task_type == 'classification':\n",
        "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "    # Treinar o modelo\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Avaliar no conjunto de teste\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    print(f\"Acurácia no conjunto de teste: {accuracy:.4f}\")\n",
        "    print(\"\\nRelatório de Classificação:\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "else:  # Regressão\n",
        "    model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "\n",
        "    # Treinar o modelo\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Avaliar no conjunto de teste\n",
        "    y_pred = model.predict(X_test)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "\n",
        "    print(f\"R² no conjunto de teste: {r2:.4f}\")\n",
        "    print(f\"RMSE no conjunto de teste: {rmse:.4f}\")"
      ],
      "metadata": {
        "id": "cPsWVqlZAGQh"
      },
      "id": "cPsWVqlZAGQh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importância das Features"
      ],
      "metadata": {
        "id": "kk79klggAKdK"
      },
      "id": "kk79klggAKdK"
    },
    {
      "cell_type": "code",
      "source": [
        " #Obter importância das features\n",
        "feature_importances = pd.DataFrame({\n",
        "    'feature': X.columns,\n",
        "    'importance': model.feature_importances_\n",
        "}).sort_values('importance', ascending=False)\n",
        "\n",
        "# Visualizar importância das features\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x='importance', y='feature', data=feature_importances.head(15))\n",
        "plt.title('Importância das Features')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Exibir tabela com importância das features\n",
        "feature_importances.head(15)"
      ],
      "metadata": {
        "id": "eLw-xkM-ANtg"
      },
      "id": "eLw-xkM-ANtg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Salvar o pipeline otimizado\n",
        "optimal_pipeline.save('optimal_pipeline')\n",
        "print(\"Pipeline salvo com sucesso!\")\n",
        "\n",
        "# Carregar o pipeline (em um novo projeto ou sessão)\n",
        "loaded_pipeline = DataPipeline.load('optimal_pipeline')\n",
        "print(\"Pipeline carregado com sucesso!\")\n",
        "\n",
        "# Verificar se o pipeline carregado funciona corretamente\n",
        "df_new = df.copy()  # Simular novos dados\n",
        "df_new_transformed = loaded_pipeline.transform(df_new, target_col=target_col)\n",
        "print(f\"Novos dados transformados: {df_new_transformed.shape}\")"
      ],
      "metadata": {
        "id": "jmELPDktAWgw"
      },
      "id": "jmELPDktAWgw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Usando o Pipeline para Novas Previsões"
      ],
      "metadata": {
        "id": "9IR7PFmMAdOQ"
      },
      "id": "9IR7PFmMAdOQ"
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_with_cafe_pipeline(new_data, target_col=None, pipeline_path='optimal_pipeline'):\n",
        "    \"\"\"\n",
        "    Usa um pipeline CAFE salvo para transformar novos dados e fazer previsões.\n",
        "\n",
        "    Args:\n",
        "        new_data: DataFrame com novos dados\n",
        "        target_col: Nome da coluna alvo (opcional, para preservação)\n",
        "        pipeline_path: Caminho do pipeline salvo\n",
        "\n",
        "    Returns:\n",
        "        DataFrame com os dados transformados\n",
        "    \"\"\"\n",
        "    # Carregar o pipeline\n",
        "    pipeline = DataPipeline.load(pipeline_path)\n",
        "    print(\"Pipeline carregado com sucesso!\")\n",
        "\n",
        "    # Transformar os novos dados\n",
        "    transformed_data = pipeline.transform(new_data, target_col=target_col)\n",
        "    print(f\"Dados transformados: {transformed_data.shape}\")\n",
        "\n",
        "    return transformed_data\n",
        "\n",
        "# Simular novos dados (usando o mesmo DataFrame para demonstração)\n",
        "new_data = df.copy()\n",
        "transformed_data = predict_with_cafe_pipeline(new_data, target_col=target_col)\n",
        "\n",
        "# Fazer previsões com o modelo treinado\n",
        "if target_col in transformed_data.columns:\n",
        "    X_new = transformed_data.drop(columns=[target_col])\n",
        "else:\n",
        "    X_new = transformed_data\n",
        "\n",
        "predictions = model.predict(X_new)\n",
        "print(f\"Previsões feitas para {len(predictions)} amostras.\")\n",
        "\n",
        "# Ver algumas previsões\n",
        "pd.DataFrame({\n",
        "    'Previsão': predictions,\n",
        "    'Real (se disponível)': new_data[target_col].values if target_col in new_data.columns else ['N/A'] * 10\n",
        "})"
      ],
      "metadata": {
        "id": "ZdtanpwsAoTG"
      },
      "id": "ZdtanpwsAoTG",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}